{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1HElPikxjNE0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROBLEM 1\n",
        "\n",
        "# PART A\n",
        "def gram_schmidt(X):\n",
        "    # X is an n-by-p matrix.\n",
        "    # Returns U an orthonormal matrix.\n",
        "    # eps is a threshold value to identify if a vector\n",
        "    # is nearly a zero vector.\n",
        "    eps = 1e-12\n",
        "\n",
        "    n, p = X.shape\n",
        "    U = np.zeros((n, 0))\n",
        "    for j in range(p):\n",
        "        # Get the j-th column of matrix X\n",
        "        v = X[:, j]\n",
        "\n",
        "        v = v - U@U.T@v\n",
        "\n",
        "        if np.linalg.norm(v) > eps:\n",
        "          u = v / (v@v) ** 0.5\n",
        "\n",
        "          u = u.reshape(-1,1)\n",
        "\n",
        "          U = np.append(U, u, 1)\n",
        "    return U\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tSe2-_5cjWZ1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART B\n",
        "\n",
        "def hilbert_matrix(n):\n",
        "    X = np.array([[1.0 / (i + j - 1) for i in range(1, n + 1)] for j in range(1, n + 1)])\n",
        "    return X\n",
        "\n",
        "hilbert = hilbert_matrix(7)\n",
        "orthonormal_hilbert = gram_schmidt(hilbert)\n",
        "\n",
        "error_matrix = np.identity(7) - orthonormal_hilbert.T @ orthonormal_hilbert\n",
        "\n",
        "error_rate = np.linalg.norm(error_matrix, ord=1)\n",
        "print(error_rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zPAo5oztFnd",
        "outputId": "c250316f-f59c-44b5-81e5-58ec04bc5fd1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2504636824142552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def modified_gram_schmidt(X):\n",
        "    # Define a threshold value to identify if a vector\n",
        "    # is nearly a zero vector.\n",
        "    eps = 1e-12\n",
        "\n",
        "    n, p = X.shape\n",
        "    U = np.zeros((n, 0))\n",
        "\n",
        "    for j in range(p):\n",
        "        # Get the j-th column of matrix X\n",
        "        v = X[:, j]\n",
        "        for i in range(j):\n",
        "            # Compute and subtract the projection of\n",
        "            # vector v onto the i-th column of U\n",
        "            v = v - np.dot(U[:, i], v) * U[:, i]\n",
        "        v = np.reshape(v, (-1, 1))\n",
        "        # Check whether the vector we get is nearly\n",
        "        # a zero vector\n",
        "        if np.linalg.norm(v) > eps:\n",
        "            # Normalize vector v and append it to U\n",
        "            U = np.hstack((U, v / np.linalg.norm(v)))\n",
        "\n",
        "    return U"
      ],
      "metadata": {
        "id": "6Buvgdxzje6G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART C\n",
        "\n",
        "hilbert = hilbert_matrix(7)\n",
        "orthonormal_hilbert = modified_gram_schmidt(hilbert)\n",
        "\n",
        "error_matrix = np.identity(7) - orthonormal_hilbert.T @ orthonormal_hilbert\n",
        "\n",
        "error_rate = np.linalg.norm(error_matrix, ord=1)\n",
        "print(error_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7gBFKpFt9d5",
        "outputId": "9160b4a1-f289-4459-b915-19f4e2947d60"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.949993888719218e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the modified gram schmidt just subtracts the projections from the prior calculated unit vectors one by one. I'm assuming that doing this step one by one somehow reduces error compared to when the projection of a particular vector v is calculated over the existing basis"
      ],
      "metadata": {
        "id": "8hQwZ6YHuUXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 6 PART A AND B\n",
        "\n",
        "d = np.load('face_emotion_data.npz')\n",
        "X = d['X']\n",
        "y = d['y']\n",
        "\n",
        "n, p = np.shape(X)\n",
        "\n",
        "# error rate for regularized least squares\n",
        "error_RLS = np.zeros((8, 7))\n",
        "# error rate for truncated SVD\n",
        "error_SVD = np.zeros((8, 7))\n",
        "\n",
        "# SVD parameters to test\n",
        "k_vals = np.arange(9) + 1\n",
        "length_k = len(k_vals)\n",
        "\n",
        "param_err_SVD = np.zeros(length_k)\n",
        "\n",
        "# RLS parameters to test\n",
        "lambda_vals = np.array([0, 0.5, 1, 2, 4, 8, 16])\n",
        "length_l = len(lambda_vals)\n",
        "\n",
        "param_err_RLS = np.zeros(length_l)\n",
        "\n",
        "\n",
        "\n",
        "for h in range (8):\n",
        "  i_range = np.arange(128)\n",
        "  holdout_index = np.full(128,False)\n",
        "  for i in range(16*h,16*(h+1)):\n",
        "    holdout_index[i] = True\n",
        "\n",
        "  testing_index = np.logical_not(holdout_index)\n",
        "\n",
        "  X_train = X[testing_index, :]\n",
        "  y_train = y[testing_index, :]\n",
        "  X_holdout = X[holdout_index, :]\n",
        "  y_holdout = y[holdout_index, :]\n",
        "\n",
        "\n",
        "  for j in range(7):\n",
        "    length = X_train.shape[0]\n",
        "    j_range = np.arange(length)\n",
        "\n",
        "    true_testing_index = np.full(length,False)\n",
        "    for k in range(16*j,16*(j+1)):\n",
        "      true_testing_index[k] = True\n",
        "    true_holdout_index = np.logical_not(true_testing_index)\n",
        "\n",
        "    Xh = X_train[true_testing_index, :]\n",
        "    yh = y_train[true_testing_index, :]\n",
        "    Xt = X_train[true_holdout_index, :]\n",
        "    yt = y_train[true_holdout_index, :]\n",
        "\n",
        "\n",
        "    U, S, Vh = np.linalg.svd(Xt, full_matrices=False)\n",
        "\n",
        "\n",
        "    # SVD Testing\n",
        "\n",
        "    w = np.zeros((p, length_k))\n",
        "\n",
        "    for i in range(length_k):\n",
        "      k = k_vals[i]\n",
        "\n",
        "      v_k = Vh[0:k, :]\n",
        "      s_k = S[0: k]\n",
        "      u_k = U[:, 0:k]\n",
        "\n",
        "      w[:, i] = np.dot(v_k.T, np.diag(1 / s_k)).dot(np.dot(u_k.T, yt)).T\n",
        "\n",
        "      w_reshaped = np.reshape(w[:, i], (p, 1))\n",
        "      dot_product = np.dot(Xh, w_reshaped)\n",
        "      yp = np.sign(dot_product)\n",
        "      param_err_SVD[i] = np.mean(yp != yh)\n",
        "\n",
        "    param_opt = np.argmin(param_err_SVD)\n",
        "\n",
        "    # Calculate true error\n",
        "    param_opt_vector = w[:, param_opt]\n",
        "    reshaped_param_opt_vector = np.reshape(param_opt_vector, (p, 1))\n",
        "    dot_product = np.dot(X_holdout, reshaped_param_opt_vector)\n",
        "    ypp = np.sign(dot_product)\n",
        "    error_SVD[h, j] = np.mean(ypp != y_holdout)\n",
        "\n",
        "\n",
        "\n",
        "    # LS\n",
        "\n",
        "    w = np.zeros((p, length_l))\n",
        "\n",
        "    for i in range(length_l):\n",
        "      lam = lambda_vals[i]\n",
        "\n",
        "      S_scaled = S / (S**2 + lam)\n",
        "      diagonal_matrix = np.diag(S_scaled)\n",
        "      first_dot_product = np.dot(Vh.T, diagonal_matrix)\n",
        "      second_dot_product = np.dot(first_dot_product, np.dot(U.T, yt))\n",
        "      w[:, i] = second_dot_product.T\n",
        "\n",
        "      column_vector = w[:, i]\n",
        "      reshaped_column_vector = np.reshape(column_vector, (p, 1))\n",
        "      dot_product = np.dot(Xh, reshaped_column_vector)\n",
        "      yp = np.sign(dot_product)\n",
        "\n",
        "      param_err_RLS[i] = np.mean(yp != yh)\n",
        "\n",
        "    param_opt = np.argmin(param_err_RLS)\n",
        "\n",
        "    # Calculate true error\n",
        "    column_vector = w[:, param_opt]\n",
        "    reshaped_column_vector = np.reshape(column_vector, (p, 1))\n",
        "    dot_product = np.dot(X_holdout, reshaped_column_vector)\n",
        "    ypp = np.sign(dot_product)\n",
        "    error_RLS[h, j] = np.mean(ypp != y_holdout)\n",
        "\n",
        "\n",
        "\n",
        "SVD_error = np.mean(error_SVD)\n",
        "RLS_error = np.mean(error_RLS)\n",
        "\n",
        "print(SVD_error)\n",
        "print(RLS_error)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_zJ1buVV3P7",
        "outputId": "d0310f69-d8d9-4421-ee34-3f81b5e3fc09"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11160714285714286\n",
            "0.04799107142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 6 PART C\n",
        "\n",
        "d = np.load('face_emotion_data.npz')\n",
        "X = d['X']\n",
        "\n",
        "augmented_features = X @ np.random.rand(9,3)\n",
        "X = np.hstack((X, augmented_features))\n",
        "y = d['y']\n",
        "\n",
        "n, p = np.shape(X)\n",
        "\n",
        "# error rate for regularized least squares\n",
        "error_RLS = np.zeros((8, 7))\n",
        "# error rate for truncated SVD\n",
        "error_SVD = np.zeros((8, 7))\n",
        "\n",
        "# SVD parameters to test\n",
        "k_vals = np.arange(9) + 1\n",
        "length_k = len(k_vals)\n",
        "\n",
        "param_err_SVD = np.zeros(length_k)\n",
        "\n",
        "# RLS parameters to test\n",
        "lambda_vals = np.array([0, 0.5, 1, 2, 4, 8, 16])\n",
        "length_l = len(lambda_vals)\n",
        "\n",
        "param_err_RLS = np.zeros(length_l)\n",
        "\n",
        "\n",
        "\n",
        "for h in range (8):\n",
        "  i_range = np.arange(128)\n",
        "  holdout_index = np.full(128,False)\n",
        "  for i in range(16*h,16*(h+1)):\n",
        "    holdout_index[i] = True\n",
        "\n",
        "  testing_index = np.logical_not(holdout_index)\n",
        "\n",
        "  X_train = X[testing_index, :]\n",
        "  y_train = y[testing_index, :]\n",
        "  X_holdout = X[holdout_index, :]\n",
        "  y_holdout = y[holdout_index, :]\n",
        "\n",
        "\n",
        "  for j in range(7):\n",
        "    length = X_train.shape[0]\n",
        "    j_range = np.arange(length)\n",
        "\n",
        "    true_testing_index = np.full(length,False)\n",
        "    for k in range(16*j,16*(j+1)):\n",
        "      true_testing_index[k] = True\n",
        "    true_holdout_index = np.logical_not(true_testing_index)\n",
        "\n",
        "    Xh = X_train[true_testing_index, :]\n",
        "    yh = y_train[true_testing_index, :]\n",
        "    Xt = X_train[true_holdout_index, :]\n",
        "    yt = y_train[true_holdout_index, :]\n",
        "\n",
        "\n",
        "    U, S, Vh = np.linalg.svd(Xt, full_matrices=False)\n",
        "\n",
        "\n",
        "    # SVD Testing\n",
        "\n",
        "    w = np.zeros((p, length_k))\n",
        "\n",
        "    for i in range(length_k):\n",
        "      k = k_vals[i]\n",
        "\n",
        "      v_k = Vh[0:k, :]\n",
        "      s_k = S[0: k]\n",
        "      u_k = U[:, 0:k]\n",
        "\n",
        "      w[:, i] = np.dot(v_k.T, np.diag(1 / s_k)).dot(np.dot(u_k.T, yt)).T\n",
        "\n",
        "      w_reshaped = np.reshape(w[:, i], (p, 1))\n",
        "      dot_product = np.dot(Xh, w_reshaped)\n",
        "      yp = np.sign(dot_product)\n",
        "      param_err_SVD[i] = np.mean(yp != yh)\n",
        "\n",
        "    param_opt = np.argmin(param_err_SVD)\n",
        "\n",
        "    # Calculate true error\n",
        "    param_opt_vector = w[:, param_opt]\n",
        "    reshaped_param_opt_vector = np.reshape(param_opt_vector, (p, 1))\n",
        "    dot_product = np.dot(X_holdout, reshaped_param_opt_vector)\n",
        "    ypp = np.sign(dot_product)\n",
        "    error_SVD[h, j] = np.mean(ypp != y_holdout)\n",
        "\n",
        "\n",
        "\n",
        "    # LS\n",
        "\n",
        "    w = np.zeros((p, length_l))\n",
        "\n",
        "    for i in range(length_l):\n",
        "      lam = lambda_vals[i]\n",
        "\n",
        "      S_scaled = S / (S**2 + lam)\n",
        "      diagonal_matrix = np.diag(S_scaled)\n",
        "      first_dot_product = np.dot(Vh.T, diagonal_matrix)\n",
        "      second_dot_product = np.dot(first_dot_product, np.dot(U.T, yt))\n",
        "      w[:, i] = second_dot_product.T\n",
        "\n",
        "      column_vector = w[:, i]\n",
        "      reshaped_column_vector = np.reshape(column_vector, (p, 1))\n",
        "      dot_product = np.dot(Xh, reshaped_column_vector)\n",
        "      yp = np.sign(dot_product)\n",
        "\n",
        "      param_err_RLS[i] = np.mean(yp != yh)\n",
        "\n",
        "    param_opt = np.argmin(param_err_RLS)\n",
        "\n",
        "    # Calculate true error\n",
        "    column_vector = w[:, param_opt]\n",
        "    reshaped_column_vector = np.reshape(column_vector, (p, 1))\n",
        "    dot_product = np.dot(X_holdout, reshaped_column_vector)\n",
        "    ypp = np.sign(dot_product)\n",
        "    error_RLS[h, j] = np.mean(ypp != y_holdout)\n",
        "\n",
        "\n",
        "\n",
        "SVD_error = np.mean(error_SVD)\n",
        "RLS_error = np.mean(error_RLS)\n",
        "\n",
        "print(SVD_error)\n",
        "print(RLS_error)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHAOPPjJdrtm",
        "outputId": "6fee477d-faa4-4c0c-b921-20f0d4a906d7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10825892857142858\n",
            "0.052455357142857144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Part C, after running the simulation several times, it seems that adding on these features doesn't really improve the performance. This makes sense as they are merely linear representations of existing features, there is no additional information. So, the algorithm is not training on any new data."
      ],
      "metadata": {
        "id": "VfI6G5sYjMJz"
      }
    }
  ]
}